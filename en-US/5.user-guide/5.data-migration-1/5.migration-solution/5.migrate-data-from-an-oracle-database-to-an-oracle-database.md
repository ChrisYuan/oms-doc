Create a project to migrate data from an Oracle tenant of OceanBase Database to an Oracle database 
=======================================================================================================================

This topic describes how to use OceanBase Migration Service (OMS) to migrate data from an Oracle tenant of OceanBase Database to an Oracle database. 

Background information 
-------------------------------------------

You can create a data migration project in the OMS console to migrate the existing business data and incremental data from an Oracle tenant of OceanBase Database to an Oracle database through schema migration, full migration, and incremental migration. 

The Oracle database supports the following modes: primary database only, standby database only, and primary/standby databases. The following table describes the data migration operations supported by each migration mode. 


|           Mode            |                                                                         Supported operations                                                                         |
|---------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Primary database only     | Schema migration, full migration, incremental migration, full verification, and reverse incremental migration                                                        |
| Standby database only     | An Oracle database in standby database only mode cannot serve as the destination for data migration.                                                                 |
| Primary/standby databases | Primary database: schema migration, full migration, and incremental migration  Standby database: full verification and reverse incremental migration |


OMS allows you to aggregate data from multiple tables in an Oracle tenant of OceanBase Database to one table in an Oracle database through full migration and incremental migration, without schema migration. The aggregation and synchronization feature has the following limits:

* For full or incremental migration, the destination table must contain all columns that exist in the source table. Otherwise, OMS returns an error.

  

* The source table must contain a primary key column.

  

* The destination table can contain a column that does not exist in the source table.

  




Prerequisites 
----------------------------------

* You have created a corresponding schema in the destination database. OMS allows you to migrate tables and columns. You must create a corresponding schema in the destination database before migration.

  

* You have created dedicated database users in the source Oracle tenant of OceanBase Database and the destination Oracle database for data migration and granted the corresponding privileges to the users. For more information, see [Create and authorize a database user](/en-US/5.user-guide/5.data-migration-1/4.preparation/1.create-and-authorize-a-database-user.md).

  

* If you want to migrate data from a table without a primary key, create the `__oceanbase_inner_drc_user` user under the corresponding tenant and grant the required privileges to the user. 

  * Create a user

    ```sql
    create user __oceanbase_inner_drc_user identified by '1****';
    ```

    
  
  * Grant privileges

    ```sql
    grant select on *.* to __oceanbase_inner_drc_user;
    ```

    
  

  




Limits 
---------------------------

* Incremental data migration is not supported for a table whose data in all columns is of the following three large object (LOB) types: BLOB, CLOB, and NCLOB.

  

* If a table does not have the primary key and contains data of the LOB type, the reverse incremental migration of the table can suffer poor data quality.

  

* You cannot migrate data from a non-template-based subpartitioned table in an Oracle tenant of OceanBase Database to an Oracle database.

  

* You can aggregate only tables with primary keys.

  

* Chinese characters are not allowed for the name of the table to be migrated and column names.

  

* OMS supports Oracle Database 10g Release 2, 11g, 12c, 18c, and 19c.

  

* When you migrate data from OceanBase Database V1.4.x, OMS does not support primary keys that contain data of the FLOAT or DOUBLE type.

  

* OMS supports character sets of Oracle databases and Oracle tenants of OceanBase Database. The field length varies with the type of the data migration task.

  

* To migrate data from a table without a primary key, you must add a hidden column to the destination table. However, if the destination Oracle database is earlier than 12c, you must add a non-hidden column to the destination table.

  

* Tables that contain the `pk` and `not null uk` fields have primary keys and do not contain function-based unique keys. If the table in the source Oracle tenant of OceanBase Database contains function-based unique keys in virtual columns or OceanBase Database is earlier than V2.2.77 (excluding V2.2.77), OMS cannot accurately identify whether the table contains function-based unique keys and therefore cannot accurately determine whether the table has a primary key. This slows down full migration and full verification and causes a risk of data inconsistency during incremental synchronization. 

  During incremental synchronization, OMS processes data in parallel based on their unique constraints. If a table contains function-based unique keys, the related transaction operations must be performed in sequence during incremental synchronization. Otherwise, data inconsistency may occur. The result of determining whether a table contains function-based unique keys must be delivered by the control layer.
  

* If the source table contains the `OMS_PK_INCRMT` field, the JDBC connector exits during a DML operation during incremental synchronization of the table. The incremental synchronization process is interrupted and cannot be recovered.

  

* OMS does not support expression-based indexes.

  

* If you do not specify the **DDL for Schema Change** field when you create the project, you must comply with the following rules to add or delete columns in the source database:

  * Add a column in the destination database first and then in the source database.

    
  
  * Delete a column in the destination database first and then in the source database.

    
  

  

* When you migrate data from an Oracle tenant of OceanBase Database earlier than V3.2x to an Oracle database, the `row movement` operation causes the following problems:

  In a multi-partition table with a globally unique index, if you update the value of the partitioning key of the table, data will be deleted from the old partitions and inserted to the new partitions in the Oracle tenant of OceanBase Database. liboblog cannot determine the dependency of data changes between partitions during migration and may output the INSERT logs first and then the DELETE logs to OMS. OMS may insert new data in the destination database during the replay of the INSERT logs but then delete the inserted data during the replay of the DELETE logs due to the unique index. This results in data loss during the migration process.
  




Supported DDL operations for incremental migration and limits 
----------------------------------------------------------------------------------

### Supported DDL operations 

* `create table`

  You can create a partitioned table but cannot execute the `create table as select` statement.
  

* `drop table`

  

* `truncate table`

  

* `add partition`

  You can add partitions and subpartitions by using Range or List partitioning. Hash partitioning is not supported.
  

* `drop partition`

  You can delete one or more partitions or subpartitions. You can add the `UPDATE GLOBAL INDEXES` option when deleting a partition. Other options are ignored.
  

* `truncate partition`

  You can truncate one or more partitions or subpartitions. You can add the `UPDATE INDEXES` option when truncating a partition. Other options are discarded.
  

* `rename table` or `alter table rename`

  

* `alter table add column`

  

* `alter table modify column`

  **Notice**

  

  You can only extend the column length. You cannot modify the column type.
  

* `create index`

  

* `drop index`

  

* Operations for adding and removing comments of tables or columns

  




### Limits 

* Only DDL operations for incremental migration are supported. If the table to be synchronized involves other types of DDL operations, the migration may fail and cause unrecoverable data exceptions.

  

* Frequent DDL operations on a table are not supported. After the Store finishes a DDL operation, which can be determined by the checkpoint, it proceeds to the next DDL operation. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

  

* Make sure that no DDL operations are performed before you create a Store and during the start of the Store. If log pulling is involved, make sure that no DDL operations are performed between the start time of pulling and the current time. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

  

* The tables before and after the `rename table` statement must be those to be synchronized or those do not require synchronization.

  

* If you delete an unnamed primary key, the corresponding constraint whose name starts with `SYS_C` in the Oracle database is deleted. If you perform inter-database data migration or synchronization, for example, from an Oracle database to an OceanBase database, the primary keys in the OceanBase database cannot be deleted because they are different from those in the Oracle database.

  

* When you migrate data from an Oracle tenant of OceanBase Database to an Oracle database, you cannot perform a DDL operation that changes a table with a primary key to a table without a primary key. 

  * If a table in the Oracle tenant of OceanBase Database has a primary key, all DDL operations are supported.

    
  
  * If a table in the Oracle tenant of OceanBase Database has only a non-null unique key, a DDL operation that removes the non-null unique key is not supported.

    
  

  

* A table creation DDL operation that involves the `case when index` statement cannot be synchronized.

  

* If you enable DDL operations for incremental data migration, the `drop index` command is executed on all indexes, which may cause index loss in the destination database.

  




Create a data migration project 
----------------------------------------------------

1. Create a data migration project. 

   1. Log on to the OMS console.

      
   
   2. In the left-side navigation pane, click **Data Migration** .

      
   
   3. On the **Data Migration** page, click **Create Migration Project** in the upper-right corner.

      
   

   

2. On the **Select the source and the destination** page, specify the fields. 

   

   |         Field          |                                                                                                                                                                                                                                                                                                                                          Description                                                                                                                                                                                                                                                                                                                                          |
   |------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
   | Migration Project Name | The name must not exceed 64 characters in length and can contain Chinese characters, digits, and letters.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
   | Tag                    | Click the field and select a tag from the drop-down list. You can also click **Manage Tags** to create, modify, or delete tags. For more information, see [Manage data migration projects by using tags](/en-US/5.user-guide/5.data-migration-1/6.migration-project-management/6.manage-project-tags.md).                                                                                                                                                                                                                                                                                                                                                                                                                                        |
   | Source Node            | If you have created Oracle tenants in OceanBase Database as data sources, select one from the drop-down list. Otherwise, click **Add Data Source** in the drop-down list, and add a data source in the dialog box on the right. For more information, see [Add OceanBase Database physical tables as data source](/en-US/5.user-guide/3.manage-data-sources/1.add-a-data-source/1.add-an-oceanbase-data-source-1/1.add-an-oceanbase-data-source.md).  **Notice**  If the source data source is not bound to an OCP cluster, the system prompts that the data migration project does not support incremental migration. To enable incremental migration, click **Edit Data Source** next to the prompt, and bind the data source to an OCP cluster. |
   | Destination Node       | If you have created Oracle data sources, select one from the drop-down list. Otherwise, click **Add Data Source** in the drop-down list, and add a data source in the dialog box on the right. For more information, see [Add an Oracle data source](/en-US/5.user-guide/3.manage-data-sources/1.add-a-data-source/3.add-an-oracle-data-source.md). You can select an Oracle data source in primary database only mode or primary/standby databases mode. An Oracle data source in standby database only mode cannot serve as the destination for data migration. This topic describes how to create a data migration project with an Oracle data source in primary/standby databases mode.                                    |

   

3. Click **Next** .

   

4. On the **Select migration types and objects** page, specify **Migration Type** for the migration task based on your business needs. 

   Migration types include **Schema Migration** , **Full Migration** , **Incremental Migration** , **Full Verification** , and **Reverse Incremental Migration** . If the Oracle tenant of OceanBase Database is not bound to an OCP cluster, you cannot select **Incremental Migration** . 

   If you select **Full Migration** , we recommend that you select **Full Verification** as well. After the incremental data is synchronized to the destination database, a full verification task is initiated for the migrated data tables in the source and destination databases. 

   **Incremental Migration** involves **DML for Data Change** (`Insert`, `Delete`, and `Update`) and **DDL for Schema Change** . You can select the operations as needed. If the source and destination databases use different character sets, OMS does not support modifications of schema fields. If you select **Incremental Migration** but do not select all DML operations in the DML for Data Change section, you cannot select **Full Verification** .
   

5. On the **Select migration types and objects** page, select the migration objects. 

   You can select the migration objects in one of the following two ways: **Specified object** and **Matching rules** . If you select **DDL for Schema Change** , only the **Matching rules** option is available. 
   * If you select **Specified object** , select the objects to be migrated on the left, and click **\>** to add them to the list on the right. You can select tables and views of one or more databases for migration. 

     **Notice**

     
     * Chinese characters are not allowed for the name of the table to be migrated and column names.

       
     
     * If the database or table name contains a double dollar sign ($$), you cannot create the migration project.

       
     

     

     When you migrate data from an Oracle tenant of OceanBase Database to an Oracle database, OMS allows you to import objects through text, rename object names, set row filters, view column information, and remove one or all objects to be migrated. 
     

     |      Action       |                                                                                                                                                                                                                                                                                                                                                                                                                             Steps                                                                                                                                                                                                                                                                                                                                                                                                                             |
     |-------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
     | Import Objects    | 1. In the list on the right of the **Data Table** section, click **Import Objects** in the upper-right corner.   2. In the dialog box that appears, click **OK** .  **Notice**  This operation will overwrite previous selections. Proceed with caution.   3. In the **Import Migration Object** dialog box, enter the objects to be migrated, for example, `SCHEMA.TB1 | SCHEMA.TB2 |`.  We recommend that you migrate no more than 10,000 objects at a time.   4. Click **Validate** .   5. After the validation succeeds, click **OK** .                                                                            |
     | Rename            | 1. In the list on the right of the **Data Table** section, move the pointer over the target object.   2. Click **Rename** .   3. Enter a new name and click **OK** .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
     | Settings          | OMS allows you to set `WHERE` conditions to filter data by row and view column information.  1. In the list on the right of the **Data Table** section, move the pointer over the target object.   2. Click **Settings** .   3. In the **Settings** dialog box, enter a `WHERE` clause of a standard SQL statement to configure row filtering.  Only the data meeting the `WHERE` condition is synchronized to the destination data source, thereby filtering data by row. Add escape characters (\`) for keywords of data sources.   4. Click **OK** .  You can also view column information of the migration object in the **View Column** section.    |
     | Remove/Remove All | OMS allows you to remove one or all migration objects.  * Remove a single migration object In the list on the right of the **Data Table** section, move the pointer over the target object, and click **Remove** . The migration object is removed.   * Remove all migration objects In the list on the right of the **Data Table** section, click **Remove All** in the upper-right corner. In the dialog box that appears, click **OK** to remove all migration objects.                                                                                                                                                                                                                                                 |

     
   
   * If you select **Matching rules** , you must configure matching rules. For more information, see [Configure matching rules for migration objects](/en-US/5.user-guide/5.data-migration-1/7.set-a-blacklist-and-a-whitelist.md).

     
   

   

6. Click **Next** . On the **Migration Options** page, specify the fields. 

   

   |     Category      |                                  Field                                   |                                                                                                                                                       Description                                                                                                                                                        |
   |-------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
   | Basic Settings    | Concurrency for Full Migration                                           | The value can be **Smooth** , **Normal** , or **Fast** . Full data migration tasks with different performance settings consume different resources.  You can also modify the configurations of the specific Checker to customize the concurrency.                                                        |
   | Basic Settings    | Full Verification Concurrency                                            | The value can be **Smooth** , **Normal** , or **Fast** . Different quantities of resources of the source and destination databases are consumed at different concurrencies.  You can also modify the configurations of the specific Checker to customize the concurrency.                                |
   | Basic Settings    | Incremental Record Retention Time                                        | The duration that incremental parsed files are cached in OMS. A longer retention period indicates more disk space occupied by the Store component of OMS.                                                                                                                                                                |
   | Advanced Settings | Whether to Allow Destination Table to Be Not Empty During Full Migration | When a non-empty destination table is allowed for full migration, full verification runs based on the `in` condition and does not need to be removed.                                                                                                                                                                    |
   | Advanced Settings | Whether to Allow Post-indexing                                           | You can specify whether to allow post-indexing after full migration is completed. Post-indexing can shorten the time of full migration.  **Notice**  To enable this feature, select both **Schema Migration** and **Full Migration** on the **Select migration types and objects** page. |

   

7. Click **Precheck** to start precheck on the data migration project. 

   During the precheck, OMS checks whether the database user has the read and write privileges and whether the network connections of the databases meet the requirements. A data migration project can be started only after it passes all check items. If the precheck fails, identify the cause, fix the problem, and run the precheck again until it succeeds. You can modify the system configurations to skip a precheck item.
   

8. Click **Start Task** to start tasks of the project such as schema migration and full migration. 

   If you do not want to immediately start the project, click **Save** to go to the details page of the data migration project. You can start the project later as needed. For more information about project details, see [View details of a data migration project](/en-US/5.user-guide/5.data-migration-1/6.migration-project-management/1.view-migration-task-details.md)
   




Start a data migration project 
---------------------------------------------------

You can start a data migration task only after it passes all check items. For any failed check items, fix the problem manually and check again. After the data migration project starts, run the selected migration types in sequence: 

1. Schema migration

   **Notice**

   

   If multiple tables are aggregated, schema migration is repeatedly performed, resulting in an error. You must click **Skip** to skip the schema migration.

   You can view the migration progress of tables and views and perform the following operations on the target object:
   * **View Creation Syntax** : View table creation syntax and modify index creation syntax. 

     Fully compatible DDL syntax executed on the OBServer is displayed. Incompatible syntax is converted before it is displayed.
     
   
   * **Modify the creation syntax and try again** : Check the error information and modify the definition of the conversion result of a failed DDL statement, and then migrate the data to the destination again.

     
   
   * **View Database Return Code** : View the DDL statements executed on the OBServer and the execution error information of a failed schema migration task.

     
   
   * **Retry** / **Retry All Failed Objects** : Retry failed schema migration tasks one by one or retry all failed tasks at a time.

     
   
   * **Skip** / **Batch Skip** : Skip failed schema migration tasks one by one or skip multiple failed tasks at a time. To skip multiple failed tasks at a time, click **Batch Skip** in the upper-right corner. When you skip an object, its index is also skipped.

     
   
   * **Remove** / **Batch Remove** : Remove failed schema migration tasks one by one or remove multiple failed tasks at a time. To remove multiple failed tasks at a time, click **Batch Remove** in the upper-right corner. When you remove an object, its index is also removed.

     
   

   

2. Migrate the existing data from tables in the source database to the corresponding tables in the destination database. You can view table objects and table indexes on the **Full Migration** page. The status of the full migration changes to Completed only after migration of the table objects and table indexes is completed. On the **Table Indexes** page, you can click **View Creation Syntax** next to the target table object to view its index creation syntax. 

   You can combine full migration with incremental migration to ensure data consistency between the source and destination databases. If any objects failed to be migrated during a full migration, the causes of the failure are displayed. 

   Full data migration inherits the database and table mapping rules that were configured when the project was created. For more information, see [Data types and syntax conversion](/en-US/5.user-guide/5.data-migration-1/2.data-types-and-syntax-conversion.md).
   

3. Incremental migration

   The migration of changed data of the source database to the corresponding table in the destination database. Data changes include data addition, modification, and deletion. 

   When services are continuously writing data to the source database, OMS starts the incremental data pull module to pull incremental data from the source instance, parses and encapsulates the incremental data, and then stores the data in OMS, before it starts the full data migration. 

   After a full data migration task is completed, OMS starts the incremental data replay module to pull incremental data from the incremental data pull module. The incremental data is synchronized to the destination instance after being filtered, mapped, and converted. 

   In the incremental migration section, you can view the performance information of the incremental migration task, such as the migration latency, synchronization timestamp, and migration traffic. 

   When a data migration project is in the **Paused** or **Failed** state, you can modify **Current Timestamp** . When you modify the timestamp for incremental migration, you cannot select a timestamp later than the current time, and the modification may cause data duplication or loss. Proceed with caution.
   

4. Full verification

   After the full data migration and incremental data migration are completed, OMS automatically initiates a full data verification task to verify the data tables in the source database and the tables in the destination database. 

   OMS also provides corresponding APIs for you to initiate custom data verification tasks in the incremental data synchronization process. 

   You can view the information of specific columns where inconsistent data is detected. OMS runs SQL scripts to correct the data in the destination database based on the data in the source database. The correction operation is not supported if the source database has no corresponding data. 

   OMS allows you to skip full verification for migration tasks in the **Executing** state. On the **Full Verification** page, click **Skip Full Verification** . In the dialog box that appears, click **Yes** .
   

5. Forward switchover

   1. Start forward switchover

      In this step, the migration does not stop. You only confirm the switchover process that is about to start. To start the forward switchover task, click **Start Forward Switchover** . 
      **Notice**

      
      Before you start a forward switchover task, make sure that the writing status of the source data source is either Stopping or Stopped.
      
   
   2. Perform switchover precheck

      Check whether the current project status supports switchover. The precheck involves the following steps:
      * Check the synchronization latency: If the synchronization latency is within 15 seconds after incremental synchronization is started, the switchover passes this check item. If incremental synchronization is not started, the switchover automatically passes this check item.

        
      
      * Check the user write privilege on the source side.

        
      

      

      If the switchover passes the precheck, the system automatically performs the next step. If the switchover fails the precheck, the system shows the error details. 

      In this case, you can **Retry** or **Skip** the precheck. 

      After you click **Skip** , you need to click **Skip** again in the dialog box that appears.
      
   
   3. Start the destination Store

      Start incremental data pulling in the destination database. Create and start a destination Store. If the start fails, you can choose to click **Retry** or **Skip** .
      
   
   4. Confirm that writing is stopped in the source database

      In the **Confirm writing stopped on the source side** section, click **OK** . You need to ensure that no incremental data is generated from the source database.
      
   
   5. Confirm the writing stop timestamp upon synchronization completion

      OMS automatically checks whether the source and destination databases are synchronized to the same timestamp. After the check is completed, the latency and timestamp of the incremental synchronization are displayed.
      
   
   6. Stop forward synchronization

      Stop the JDBCWriter from the source database to the destination database. If the forward synchronization fails to be stopped, you can choose to click **Retry** or **Skip** .
      
   
   7. Process database objects

      In this step, database objects are migrated, additional objects are deleted, and database objects that are not migrated are added. 

      You need to click **Run** to process the database objects. For a running project, you can click **View Logs** or **Skip** . For projects that have been processed, you need to click **Mark as Complete** . After all projects have been marked as completed, proceed to the next step.
      
   
   8. Start reverse incremental migration

      In the **Start Reverse Incremental Migration** section, click **Start Reverse Incremental Migration** to start the JDBCWriter from the destination database to the source database. Wait until the **Successfully started reverse increment** message appears.
      
   

   

6. After reverse incremental migration is started, click the **Reverse Incremental Migration** tab to view detailed information such as **Start Time** and **Reverse Synchronization Performance** . 

   Performance metrics of reverse incremental migration:
   * Latency: The time consumed to synchronize changed incremental data from the destination database to the source database in the unit of seconds.

     
   
   * Migration traffic: The traffic throughput of incremental data synchronization from the destination database to the source database in the unit of MB/s.

     
   

   



