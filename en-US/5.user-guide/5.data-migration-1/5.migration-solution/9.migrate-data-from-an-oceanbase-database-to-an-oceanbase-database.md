Migrate data within OceanBase Database 
===========================================================

OceanBase Migration Service (OMS) allows you to migrate the existing business data and incremental data between the same type of tenants in OceanBase Database through schema migration, full migration, and incremental migration. 

Prerequisites 
----------------------------------

* You have created a corresponding schema in the destination tenant of OceanBase Database. OMS allows you to migrate tables and columns. You must create a corresponding schema in the destination tenant before migration.

  

* You have created dedicated database users in the source and destination tenants of OceanBase Database for data migration and granted the corresponding privileges to the users. For more information, see [Create and authorize a database user](/en-US/5.user-guide/5.data-migration-1/4.preparation/1.create-and-authorize-a-database-user.md).

  

* If you want to migrate data from a table without a primary key, create a user and grant privileges to the user as needed before migration. 

  * When you migrate data from a MySQL tenant of OceanBase Database, create the `__oceanbase_inner_drc_user` user. 

    * Create a user

      ```sql
      create user __oceanbase_inner_drc_user identified by '1****';
      ```

      
    
    * Grant privileges

      ```sql
      grant select on *.* to __oceanbase_inner_drc_user;
      ```

      
    

    
  
  * When you migrate data from an Oracle tenant of OceanBase Database, create the `__OCEANBASE_INNER_DRC_USER` user. 

    * Create a user

      ```sql
      create user '__OCEANBASE_INNER_DRC_USER'@'%' IDENTIFIED BY '1****';
      ```

      
    
    * Grant privileges

      

      |  OceanBase Database Version   |                                                                                                                                                                                                                 Statements for granting privileges                                                                                                                                                                                                                  |
      |-------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
      | Versions earlier than V2.2.77 | ```sql grant create session to '__OCEANBASE_INNER_DRC_USER'; grant select on *.* to '__OCEANBASE_INNER_DRC_USER'; ```                                                                                                                                                                                                                                                                                                                       |
      | V2.2.77 and later versions    | ```sql grant create session to '__OCEANBASE_INNER_DRC_USER'; ```  You can grant the `select` privilege on database tables to be migrated in either of the following ways: ```sql // Grant system privileges. grant select any table to '__OCEANBASE_INNER_DRC_USER'; // Grant privileges on specific database table objects. grant select on {schema}.{table} to '__OCEANBASE_INNER_DRC_USER'; ```  |

      
    

    
  

  




Limits 
---------------------------

* You can migrate data only between the same type of tenants in OceanBase Database. 

  To be specific, you can migrate data between MySQL tenants of OceanBase Database or between Oracle tenants of OceanBase Database.
  

* If you enable DDL operations for incremental data migration, the `drop index` command is executed on all indexes, which may cause index loss in the destination database.

  

* You can migrate multiple schemas in one data migration project. The maximum unit for migration is a tenant, and the minimum unit for migration is a table.

  

* You can migrate data from OceanBase Database V2.1.0 or later versions. The source and destination tenants can be created in different versions of OceanBase Database.

  

* OMS V3.2.0 and later versions allow you to migrate both tables with primary keys and tables without primary keys between tenants of OceanBase Database.

  

* Chinese characters are not allowed for the name of the table to be migrated and column names.

  

* When you migrate data from OceanBase Database V1.4.x, OMS does not support primary keys that contain data of the FLOAT or DOUBLE type.

  

* If you do not specify the **DDL for Schema Change** field when you create the project, you must comply with the following rules to add or delete columns in the source database:

  * Add a column in the destination database first and then in the source database.

    
  
  * Delete a column in the destination database first and then in the source database.

    
  

  

* When you migrate data between tenants of OceanBase Database earlier than V3.2x, the `row movement` operation causes the following problems:

  In a multi-partition table with a globally unique index, if you update the value of the partitioning key of the table, data will be deleted from the old partitions and inserted to the new partitions in OceanBase Database. liboblog cannot determine the dependency of data changes between partitions during migration and may output the INSERT logs first and then the DELETE logs to OMS. OMS may insert new data in the destination database during the replay of the INSERT logs but then delete the inserted data during the replay of the DELETE logs due to the unique index. This results in data loss during the migration process.
  

* Tables that contain the `pk` and `not null uk` fields have primary keys and do not contain function-based unique keys. If the table in the source Oracle tenant of OceanBase Database contains function-based unique keys in virtual columns or OceanBase Database is earlier than V2.2.77 (excluding V2.2.77), OMS cannot accurately identify whether the table contains function-based unique keys and therefore cannot accurately determine whether the table has a primary key. This slows down full migration and full verification and causes a risk of data inconsistency during incremental synchronization. 

  During incremental synchronization, OMS processes data in parallel based on their unique constraints. If a table contains function-based unique keys, the related transaction operations must be performed in sequence during incremental synchronization. Otherwise, data inconsistency may occur.
  




Supported DDL operations for incremental migration and limits 
----------------------------------------------------------------------------------

### Migrate data between MySQL tenants of OceanBase Database 

You can use DDL operations to migrate incremental data between MySQL tenants of OceanBase Database. 
**Notice**



If you have created an `index` in the source tenant, it also exists in the destination tenant. OMS automatically ignores the `index` without interrupting the migration process.

* Supported DDL operations for incremental migration

  * `alter table add column`

    
  
  * `alter table modify column`

    **Notice**

    

    You can only extend the column length. You cannot modify the column type.
    
  
  * `alter table alter column set default` or `alter table alter column drop default`

    
  
  * `alter table drop column`

    
  
  * `create table`

    
  
  * `drop table`

    
  
  * `truncate table`

    
  
  * `create index` or `alter table add index`

    
  
  * `drop index` or `alter table drop index`

    
  
  * `rename table` or `alter table rename`

    
  

  

* Limits of DDL operations

  * If the table to be synchronized involves DDL operations that are not supported, the migration may fail and cause unrecoverable data exceptions.

    
  
  * Frequent DDL operations on a table are not supported. After the Store finishes a DDL operation, which can be determined by the checkpoint, it proceeds to the next DDL operation. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

    
  
  * Make sure that no DDL operations are performed before you create a Store and during the start of the Store. If log pulling is involved, make sure that no DDL operations are performed between the start time of pulling and the current time. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

    
  
  * The tables before and after the `rename table` statement must be those to be synchronized or those do not require synchronization.

    
  
  * If you enable DDL operations for incremental data migration, the `drop index` command is executed on all indexes, which may cause index loss in the destination database.

    
  

  




### Migrate data between Oracle tenants of OceanBase Database 

You can use DDL operations to migrate incremental data between Oracle tenants of OceanBase Database. 

* Supported DDL operations for incremental migration

  * `create table`

    You can create a partitioned table but cannot execute the `create table as select` statement. Partitions and subpartitions are supported. You can create partitions and subpartitions by using Hash, Range, or List partitioning.
    
  
  * `drop table`

    
  
  * `truncate table`

    
  
  * `rename table` or `alter table rename`

    
  
  * `alter table add column`

    
  
  * `alter table modify column`

    **Notice**

    

    You can only extend the column length. You cannot modify the column type.
    
  
  * `create index`

    
  
  * `drop index`

    
  
  * Operations for adding and removing comments of tables or columns

    
  

  

* Limits of DDL operations

  * If the table to be synchronized involves DDL operations that are not supported, the migration may fail and cause unrecoverable data exceptions.

    
  
  * Frequent DDL operations on a table are not supported. After the Store finishes a DDL operation, which can be determined by the checkpoint, it proceeds to the next DDL operation. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

    
  
  * Make sure that no DDL operations are performed before you create a Store and during the start of the Store. If log pulling is involved, make sure that no DDL operations are performed between the start time of pulling and the current time. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

    
  
  * The tables before and after the `rename table` statement must be those to be synchronized or those do not require synchronization.

    
  
  * A table creation DDL operation that involves the `case when index` statement cannot be synchronized.

    
  
  * If you enable DDL operations for incremental data migration, the `drop index` command is executed on all indexes, which may cause index loss in the destination database.

    
  

  




Create a data migration project 
----------------------------------------------------

1. Create a data migration project. 

   1. Log on to the OMS console.

      
   
   2. In the left-side navigation pane, click **Data Migration** .

      
   
   3. On the **Data Migration** page, click **Create Migration Project** in the upper-right corner.

      
   

   

2. On the **Select the source and the destination** page, specify the fields. 

   

   |         Field          |                                                                                                                                                                                                                                                                                                                           Description                                                                                                                                                                                                                                                                                                                           |
   |------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
   | Migration Project Name | The name must not exceed 64 characters in length and can contain Chinese characters, digits, and letters.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
   | Tag                    | Click the field and select a tag from the drop-down list. You can also click **Manage Tags** to create, modify, or delete tags. For more information, see [Manage data migration projects by using tags](/en-US/5.user-guide/5.data-migration-1/6.migration-project-management/6.manage-project-tags.md).                                                                                                                                                                                                                                                                                                                                                                                                          |
   | Source Node            | If you have created OceanBase data sources, select one from the drop-down list. Otherwise, click **Add Data Source** in the drop-down list, and add a data source in the dialog box on the right. For more information, see [Add OceanBase Database physical tables as data source](/en-US/5.user-guide/3.manage-data-sources/1.add-a-data-source/1.add-an-oceanbase-data-source-1/1.add-an-oceanbase-data-source.md).  **Notice**  If the source data source is not bound to an OCP cluster, the system prompts that the data migration project does not support incremental migration. To enable incremental migration, click **Edit Data Source** next to the prompt, and bind the data source to an OCP cluster. |
   | Destination Node       | If you have created OceanBase data sources, select one from the drop-down list. Otherwise, click **Add Data Source** in the drop-down list, and add a data source in the dialog box on the right.  **Notice**  If the destination data source is not bound to an OCP cluster, the system prompts that the data migration project does not support reverse incremental migration. To enable reverse incremental migration, click **Edit Data Source** next to the prompt, and bind the data source to an OCP cluster.                                                                                                            |
   | Scenarios              | Two scenarios are available: **Data Migration** and **Active-Active Disaster Recovery** . Select **Data Migration** . For more information about the active-active disaster recovery scenario, see [Create an active-active disaster recovery project in OceanBase Database](/en-US/5.user-guide/5.data-migration-1/5.migration-solution/10.creates-an-active-active-disaster-recovery-project-for-oceanbase-databases.md). **Notice**  The source and destination data sources must be the same type of tenants in OceanBase Database.                                                                                                                                                                                          |

   

3. Click **Next** .

   

4. On the **Select migration types and objects** page, specify **Migration Type** for the migration project. 

   Migration types include **Schema Migration** , **Full Migration** , **Incremental Migration** , **Full Verification** , and **Reverse Incremental Migration** . 
   * If the source data source is not bound to an OCP cluster, you cannot select **Incremental Migration** .

     
   
   * If the destination data source is not bound to an OCP cluster, you cannot select **Reverse Incremental Migration** .

     
   
   * If you select **Active-Active Disaster Recovery** , you cannot select **Reverse Incremental Migration** .

     
   
   * If you select Full Migration or Incremental Migration, we recommend that you select **Full Verification** as well. After the incremental data is synchronized to the destination database, a full verification task is initiated for the migrated data tables in the source and destination databases. 

     **Incremental Migration** involves **DML for Data Change** (`Insert`, `Delete`, and `Update`) and **DDL for Schema Change** . You can select the operations as needed. If you select **Incremental Migration** but do not select all DML operations in the DML for Data Change section, you cannot select **Full Verification** .
     
   

   

5. On the **Select migration types and objects** page, select the migration objects. 

   You can select the migration objects in one of the following two ways: **Specified object** and **Matching rules** . If you select **DDL for Schema Change** , only the **Matching rules** option is available. 
   * If you select **Specified object** , select the objects to be migrated on the left, and click **\>** to add them to the list on the right. You can select tables and views of one or more databases for migration. 

     **Notice**

     
     * Chinese characters are not allowed for the name of the table to be migrated and column names.

       
     
     * If the database or table name contains a double dollar sign ($$), you cannot create the migration project.

       
     

     

     When you migrate data between tenants of OceanBase Database, OMS allows you to import objects through text, rename object names, set row filters, view column information, and remove one or all objects to be migrated. 
     

     |      Action       |                                                                                                                                                                                                                                                                                                                                                                                                                             Steps                                                                                                                                                                                                                                                                                                                                                                                                                             |
     |-------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
     | Import Objects    | 1. In the list on the right of the **Data Table** section, click **Import Objects** in the upper-right corner.   2. In the dialog box that appears, click **OK** .  **Notice**  This operation will overwrite previous selections. Proceed with caution.   3. In the **Import Migration Object** dialog box, enter the objects to be migrated, for example, `SCHEMA.TB1 | SCHEMA.TB2 |`.  We recommend that you migrate no more than 10,000 objects at a time.   4. Click **Validate** .   5. After the validation succeeds, click **OK** .                                                                            |
     | Rename            | 1. In the list on the right of the **Data Table** section, move the pointer over the target object.   2. Click **Rename** .   3. Enter a new name and click **OK** .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
     | Settings          | OMS allows you to set `WHERE` conditions to filter data by row and view column information.  1. In the list on the right of the **Data Table** section, move the pointer over the target object.   2. Click **Settings** .   3. In the **Settings** dialog box, enter a `WHERE` clause of a standard SQL statement to configure row filtering.  Only the data meeting the `WHERE` condition is synchronized to the destination data source, thereby filtering data by row. Add escape characters (\`) for keywords of data sources.   4. Click **OK** .  You can also view column information of the migration object in the **View Column** section.    |
     | Remove/Remove All | OMS allows you to remove one or all migration objects.  * Remove a single migration object In the list on the right of the **Data Table** section, move the pointer over the target object, and click **Remove** . The migration object is removed.   * Remove all migration objects In the list on the right of the **Data Table** section, click **Remove All** in the upper-right corner. In the dialog box that appears, click **OK** to remove all migration objects.                                                                                                                                                                                                                                                 |

     
   
   * If you select **Matching rules** , you must configure matching rules. For more information, see [Configure matching rules for migration objects](/en-US/5.user-guide/5.data-migration-1/7.set-a-blacklist-and-a-whitelist.md).

     
   

   

6. Click **Next** . On the **Migration Options** page, specify the fields. 

   

   |     Category      |                                  Field                                   |                                                                                                                                                       Description                                                                                                                                                        |
   |-------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
   | Basic Settings    | Concurrency for Full Migration                                           | The value can be **Smooth** , **Normal** , or **Fast** . Full data migration tasks with different performance settings consume different resources.  You can also modify the configurations of the specific Checker to customize the concurrency.                                                        |
   | Basic Settings    | Full Verification Concurrency                                            | The value can be **Smooth** , **Normal** , or **Fast** . Different quantities of resources of the source and destination databases are consumed at different concurrencies.  You can also modify the configurations of the specific Checker to customize the concurrency.                                |
   | Basic Settings    | Incremental Record Retention Time                                        | The duration that incremental parsed files are cached in OMS. A longer retention period indicates more disk space occupied by the Store component of OMS.                                                                                                                                                                |
   | Advanced Settings | Whether to Allow Destination Table to Be Not Empty During Full Migration | When a non-empty destination table is allowed for full migration, full verification runs based on the `in` condition and does not need to be removed.                                                                                                                                                                    |
   | Advanced Settings | Whether to Allow Post-indexing                                           | You can specify whether to allow post-indexing after full migration is completed. Post-indexing can shorten the time of full migration.  **Notice**  To enable this feature, select both **Schema Migration** and **Full Migration** on the **Select migration types and objects** page. |

   

7. Click **Precheck** to start precheck on the data migration project. 

   During the precheck, OMS checks whether the database user has the read and write privileges and whether the network connections of the databases meet the requirements. A data migration project can be started only after it passes all check items. If the precheck fails, identify the cause, fix the problem, and run the precheck again until it succeeds. You can modify the system configurations to skip a precheck item.
   

8. Click **Start Task** to start tasks of the project such as schema migration and full migration. 

   If you do not want to immediately start the project, click **Save** to go to the details page of the data migration project. You can start the project later as needed. For more information about project details, see [View details of a data migration project](/en-US/5.user-guide/5.data-migration-1/6.migration-project-management/1.view-migration-task-details.md).
   




Start a data migration project 
---------------------------------------------------

You can start a data migration project only after it passes all check items. For any failed check items, fix the problem manually and check again. After the data migration project starts, run the selected migration types in sequence: 

1. Schema migration

   You can view the migration progress of tables and views and perform the following operations on the target object:
   * **View Creation Syntax** : View table creation syntax and modify index creation syntax. 

     Fully compatible DDL syntax executed on the OBServer is displayed. Incompatible syntax is converted before it is displayed.
     
   
   * **Modify the creation syntax and try again** : Check the error information and modify the definition of the conversion result of a failed DDL statement, and then migrate the data to the destination again.

     
   
   * **View Database Return Code** : View the DDL statements executed on the OBServer and the execution error information of a failed schema migration task.

     
   
   * **Retry** / **Retry All Failed Objects** : Retry failed schema migration tasks one by one or retry all failed tasks at a time.

     
   
   * **Skip** / **Batch Skip** : Skip failed schema migration tasks one by one or skip multiple failed tasks at a time. To skip multiple failed tasks at a time, click **Batch Skip** in the upper-right corner. When you skip an object, its index is also skipped.

     
   
   * **Remove** / **Batch Remove** : Remove failed schema migration tasks one by one or remove multiple failed tasks at a time. To remove multiple failed tasks at a time, click **Batch Remove** in the upper-right corner. When you remove an object, its index is also removed.

     
   

   

2. Full migration

   The migration of the existing data from tables in the source database to corresponding tables in the OceanBase database. You can view table objects and table indexes on the **Full Migration** page. The status of the full migration changes to Completed only after migration of the table objects and table indexes is completed. On the **Table Indexes** page, you can click **View Creation Syntax** next to the target table object to view its index creation syntax. 

   You can combine full migration with incremental migration to ensure data consistency between the source and destination databases. If any objects failed to be migrated during a full migration, the causes of the failure are displayed. 

   Full data migration inherits the database and table mapping rules that were configured when the project was created. For more information, see [Data types and syntax conversion](/en-US/5.user-guide/5.data-migration-1/2.data-types-and-syntax-conversion.md).
   

3. Incremental migration

   The migration of changed data of the source database to the corresponding table in OceanBase Database. Data changes include data addition, modification, and deletion. 

   When services are continuously writing data to the source database, OMS starts the incremental data pull module to pull incremental data from the source instance, parses and encapsulates the incremental data, and then stores the data in OMS, before it starts the full data migration. 

   After a full data migration task is completed, OMS starts the incremental data replay module to pull incremental data from the incremental data pull module. The incremental data is synchronized to the destination instance after being filtered, mapped, and converted. 

   In the incremental migration section, you can view the performance information of the incremental migration task, such as the migration latency, synchronization timestamp, and migration traffic. 

   When a data migration project is in the **Paused** or **Failed** state, you can modify **Current Timestamp** . When you modify the timestamp for incremental migration, you cannot select a timestamp later than the current time, and the modification may cause data duplication or loss. Proceed with caution.
   

4. Full verification

   After the full data migration and incremental data migration are completed, OMS automatically initiates a full data verification task to verify the data tables in the source database and the tables in the destination database. 

   OMS also provides corresponding APIs for you to initiate custom data verification tasks in the incremental data synchronization process. 

   You can view the information of specific columns where inconsistent data is detected. OMS runs SQL scripts to correct the data in the destination database based on the data in the source database. The correction operation is not supported if the source database has no corresponding data. 

   OMS allows you to skip full verification for migration tasks in the **Executing** state. On the **Full Verification** page, click **Skip Full Verification** . In the dialog box that appears, click **Yes** . 

   After full verification is completed, click **Go To Next Stage** . In the dialog box that appears, click **OK** . 
   **Notice**

   

   After you enter the switchover process, you cannot re-check the current verification task for data comparison and correction.
   

5. Forward switchover

   1. Start forward switchover

      In this step, the migration does not stop. You only confirm the switchover process that is about to start. To start the forward switchover task, click **Start Forward Switchover** . 
      **Notice**

      
      Before you start a forward switchover task, make sure that the writing status of the source data source is either Stopping or Stopped.
      
   
   2. Perform switchover precheck

      Check whether the current project status supports switchover. The precheck involves the following steps:
      * Check the synchronization latency: If the synchronization latency is within 15 seconds after incremental synchronization is started, the switchover passes this check item. If incremental synchronization is not started, the switchover automatically passes this check item.

        
      
      * Check the user write privilege on the source side.

        
      

      

      If the switchover passes the precheck, the system automatically performs the next step. If the switchover fails the precheck, the system shows the error details. 

      In this case, you can **Retry/Skip** the precheck. 

      After you click **Skip** , you need to click **Skip** again in the dialog box that appears.
      
   
   3. Start the destination Store

      Start incremental data pulling in the destination database. Create and start a destination Store. If the start fails, you can choose to click **Retry** or **Skip** .
      
   
   4. Confirm that writing is stopped in the source database

      In the **Confirm writing stopped on the source side** section, click **OK** . You need to ensure that no incremental data is generated from the source database.
      
   
   5. Confirm the writing stop timestamp upon synchronization completion

      OMS automatically checks whether the source and destination databases are synchronized to the same timestamp. After the check is completed, the latency and timestamp of the incremental synchronization are displayed.
      
   
   6. Stop forward synchronization

      Stop the JDBCWriter from the source database to the destination database. If the forward synchronization fails to be stopped, you can choose to click **Retry** or **Skip** .
      
   
   7. Process database objects

      In this step, database objects are migrated, additional objects are deleted, and database objects that are not migrated are added. 

      You need to click **Run** to execute the database objects. For a running project, you can click **View Logs** or **Skip** . For projects that have been processed, you need to click **Mark as Complete** . After all projects have been marked as completed, proceed to the next step.
      
   
   8. Start reverse incremental migration

      In the **Start Reverse Incremental Migration** section, click **Start Reverse Incremental Migration** to start the JDBCWriter from the destination database to the source database. Wait until the **Successfully started reverse increment** message appears.
      
   

   

6. After reverse incremental migration is started, click the **Reverse Incremental Migration** tab to view detailed information such as **Start Time** and **Reverse Synchronization Performance** . 

   Performance metrics of reverse incremental migration:
   * Latency: The time consumed to synchronize changed incremental data from the destination database to the source database in the unit of seconds.

     
   
   * Migration traffic: The traffic throughput of incremental data synchronization from the destination database to the source database in the unit of MB/s.

     
   

   




